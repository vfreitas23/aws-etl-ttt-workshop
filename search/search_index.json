{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to AWS ETL Migration & Modernization Train-The-Trainer Workshop: This workshop contains a set of XXX hands-on labs which complementes the Day One of the ETL Migration & Modernization - Train The Trainer Workshop. Participants will build an end-to-end ETL Pipeline that will...[add details of the pipeline...] After completing the labs, the participants will have a high level understand of AWS Glue core capabilities as well as they will be able to demonstrate most of the Glue core capabilities. Workshop Parts & Steps Part 0 - PRE STEPS \u00b6 1. Setting up Cloud9 Environment Variables 2. Switching Cloud9 Role Credentials 3. Setting up Security Required Groups Inbound Rules 4. Installing Required Libraries (Boto3) Part 1 - TPCDS & RDS MySQL \u00b6 1. Preparing & Generating TPCDS Dataset 2. Populating the Amazon RDS-MySQL Database with TPCDS Dataset Part 2 - GLUE DATABASE, TABLES, CONNECTIONS, CRAWLERS, CLASSIFIERS \u00b6 1. Understanding the Glue Resources Provided (CloudFormation Resources) 2. Running the MySQL-RDS-Crawler 3. Creating a New Crawler (and a Classifier for it!) Part 3 - GLUE (STUDIO) STREAMING \u00b6 1. Understanding the Streaming Resources Provided (CloudFormation & Scripts) 2. Validating Streaming Job Logic and Data (Glue Studio Dummy Job) 3. Creating the Glue Streaming Job (Cloning Jobs!) Part 4 - ORCHESTRATION & DATA ANALYSIS \u00b6 1. Understanding the Orchestration Flow 2. Creating Glue Workflow and Glue Event Based Trigger (via CLI) 3. Creating Event Bridge Rule and Target (via CLI) 4. Starting Orchestration & Exploring and Analyzing Table's Data Cataloged in Glue Data Catalog 6. Creating Views on Top of Cataloged Tables Part 5 - DATA QUALITY & PREPARATION WITH AWS GLUE DATABREW \u00b6 1. Creating Datasets & Profiling the Data (with Quality Rules) 2. Building & Managing DataBrew Recipes 3. Operationalizing a DataBrew Project into a Glue Job.","title":"Introduction"},{"location":"#part-0-pre-steps","text":"1. Setting up Cloud9 Environment Variables 2. Switching Cloud9 Role Credentials 3. Setting up Security Required Groups Inbound Rules 4. Installing Required Libraries (Boto3)","title":"Part 0 - PRE STEPS"},{"location":"#part-1-tpcds-rds-mysql","text":"1. Preparing & Generating TPCDS Dataset 2. Populating the Amazon RDS-MySQL Database with TPCDS Dataset","title":"Part 1 - TPCDS &amp; RDS MySQL"},{"location":"#part-2-glue-database-tables-connections-crawlers-classifiers","text":"1. Understanding the Glue Resources Provided (CloudFormation Resources) 2. Running the MySQL-RDS-Crawler 3. Creating a New Crawler (and a Classifier for it!)","title":"Part 2 - GLUE DATABASE, TABLES, CONNECTIONS, CRAWLERS, CLASSIFIERS"},{"location":"#part-3-glue-studio-streaming","text":"1. Understanding the Streaming Resources Provided (CloudFormation & Scripts) 2. Validating Streaming Job Logic and Data (Glue Studio Dummy Job) 3. Creating the Glue Streaming Job (Cloning Jobs!)","title":"Part 3 - GLUE (STUDIO) STREAMING"},{"location":"#part-4-orchestration-data-analysis","text":"1. Understanding the Orchestration Flow 2. Creating Glue Workflow and Glue Event Based Trigger (via CLI) 3. Creating Event Bridge Rule and Target (via CLI) 4. Starting Orchestration & Exploring and Analyzing Table's Data Cataloged in Glue Data Catalog 6. Creating Views on Top of Cataloged Tables","title":"Part 4 - ORCHESTRATION &amp; DATA ANALYSIS"},{"location":"#part-5-data-quality-preparation-with-aws-glue-databrew","text":"1. Creating Datasets & Profiling the Data (with Quality Rules) 2. Building & Managing DataBrew Recipes 3. Operationalizing a DataBrew Project into a Glue Job.","title":"Part 5 - DATA QUALITY &amp; PREPARATION WITH AWS GLUE DATABREW"},{"location":"setup/","text":"Setup \u00b6 Perform the following steps to login to the event engine. Type Event Engine URL on to your browser. (Right click this link -> Open in new tab). Enter the hash provided to you. Accept Terms & Login. Choose \u201cEmail One-Time Password\u201d. Provide your email ID where your 9-digit OTP will be sent within 5 mins. Once you receive OTP over your email, enter it to sign in to the Team Dashboard. Click on the SSH Key and download the key to your local desktop. Click Ok once done. Click on AWS Console and Open AWS Console. You can also retrieve AWS_DEFAULT_REGION, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and AWS_SESSION_TOKEN from this Team Dashboard whenever required for your exercises. Make a note of your account ID in the top right corner of the AWS Console and store it in a notepad. Go to CloudFormation and verify that the Cloudformation templates \"dayone\", \"emr-on-eks\" and \"smstudio\" are created.","title":"** Setup **"},{"location":"setup/#setup","text":"Perform the following steps to login to the event engine. Type Event Engine URL on to your browser. (Right click this link -> Open in new tab). Enter the hash provided to you. Accept Terms & Login. Choose \u201cEmail One-Time Password\u201d. Provide your email ID where your 9-digit OTP will be sent within 5 mins. Once you receive OTP over your email, enter it to sign in to the Team Dashboard. Click on the SSH Key and download the key to your local desktop. Click Ok once done. Click on AWS Console and Open AWS Console. You can also retrieve AWS_DEFAULT_REGION, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and AWS_SESSION_TOKEN from this Team Dashboard whenever required for your exercises. Make a note of your account ID in the top right corner of the AWS Console and store it in a notepad. Go to CloudFormation and verify that the Cloudformation templates \"dayone\", \"emr-on-eks\" and \"smstudio\" are created.","title":"Setup"},{"location":"AnalysisLab/analysis-lab/","text":"","title":"Analysis lab"},{"location":"DataBrew-Lab/databrew-lab/","text":"","title":"Databrew lab"},{"location":"DummyLab/dummy-lab/","text":"","title":"Dummy lab"},{"location":"Intro/intro/","text":"","title":"Intro"},{"location":"PreSteps/pre-steps/","text":"","title":"Pre steps"},{"location":"StreamingLab/streaming-lab/","text":"","title":"Streaming lab"}]}